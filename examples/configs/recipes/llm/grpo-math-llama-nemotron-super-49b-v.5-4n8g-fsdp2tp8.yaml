defaults: ../../grpo_math_1B.yaml
grpo:
  num_prompts_per_step: 128
policy:
  model_name: nvidia/Llama-3_3-Nemotron-Super-49B-v1_5
  tokenizer:
    name: nvidia/Llama-3_3-Nemotron-Super-49B-v1_5
  max_total_sequence_length: 1024
  train_global_batch_size: 128
  dtensor_cfg:
    activation_checkpointing: true
    tensor_parallel_size: 8
    custom_parallel_plan: examples.configs.recipes.llm.llama_nemotron_super_49b_custom_plan.custom_parallel_plan
  dynamic_batching:
    enabled: true
  sequence_packing:
    enabled: false
  optimizer:
    kwargs:
      lr: 3.0e-07
  scheduler:
  - name: torch.optim.lr_scheduler.LinearLR
    kwargs:
      start_factor: 0.1
      end_factor: 1.0
      total_iters: 13
  - name: torch.optim.lr_scheduler.ConstantLR
    kwargs:
      factor: 1.0
      total_iters: 10000000000
  - milestones:
    - 13
  generation:
    vllm_cfg:
      tensor_parallel_size: 4
logger:
  wandb_enabled: true
  monitor_gpus: false
  wandb:
    project: grpo-nemotron-super-49b
    name: grpo-${data.dataset_name}-nemotron-super-49b-tp${policy.dtensor_cfg.tensor_parallel_size}
  mlflow:
    experiment_name: sft-dev
    run_name: grpo-nemotron-super-49b
cluster:
  gpus_per_node: 8
  num_nodes: 4
